# Question 516
## Question
* A company provides an API interface to customers so the customers can retrieve their financial information. Company expects a larger number of requests during peak usage times of the year.
* *The company requires the API to respond consistently with low latency to ensure customer satisfaction*. The company needs to provide a compute host for the API.
* Which solution will meet these requirements with the *LEAST operational overhead*?

## Option
* A.Use an Application Load Balancer and Amazon Elastic Container Service (Amazon ECS).
* B.Use Amazon API Gateway and AWS Lambda functions with provisioned concurrency.
* C.Use an Application Load Balancer and an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.
* D.Use Amazon API Gateway and AWS Lambda functions with reserved concurrency

## Answer
* B. Use Amazon API Gateway and AWS Lambda functions with provisioned concurrency.

## Explanation
1. A. Application Load Balancer + ECS
   * More operational overhead: You have to manage task scaling, service definitions, cluster capacity, etc.
   * ECS adds complexity compared to serverless.
2. C. ALB + EKS (Kubernetes)
   * Requires managing Kubernetes control plane, pods, nodes, networking, etc.
   * Overkill for just exposing an API unless you already use Kubernetes.
3. D. API Gateway + Lambda with reserved concurrency
   * Reserved concurrency limits the number of concurrent executions, which can protect downstream resources but does not guarantee consistent warm Lambda instances.
   * Does not eliminate cold starts, which is critical if you need low latency.

## Thinking
* 看到需要 API 可以提供給大量的人進行呼叫，基本上可以先考慮 Amazon API Gateway
* 而且 Option A, C 使用 ALB + ECS / EKS cluster，ECS/EKS Cluster 需要額外的設定，所以其實不太符合 LEAST operational overhead
* 所以目前只剩下 Option A 與 Option B，兩者差別主要是 Provisioned concurrency 與 Reserved concurrency。
* Reserved concurrency 朝字面上的意思，是先預約一個時間段的concurrency程式，無法提供一個低延遲回應（只能確保有回應)